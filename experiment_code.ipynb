{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abrarelidrisi/MRI-Segmentation/blob/main/experiment_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 1:** Defining our segmentation processes. This includes Normalizing, Gaussian blurring, Otsu Thresholding, Canny Edge Detection, KMeans Segmentation using dictionary-based temporal masks approach."
      ],
      "metadata": {
        "id": "rUJO7OfXWr_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF85orhPpfVQ"
      },
      "outputs": [],
      "source": [
        "#Importing important libraries and loading our dataset (containing of MRI scans and the ground truth (Segmented)images\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.io import loadmat\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.morphology import remove_small_objects, remove_small_holes, binary_dilation\n",
        "from scipy.ndimage import binary_dilation, binary_fill_holes\n",
        "from skimage.feature import canny\n",
        "import scipy.ndimage as ndi\n",
        "from sklearn.cluster import KMeans\n",
        "!pip install pandas\n",
        "import pandas as pd\n",
        "from skimage.filters import threshold_multiotsu\n",
        "from scipy.ndimage import gaussian_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iX9TquelaqlI"
      },
      "outputs": [],
      "source": [
        "#Since I'll be using edge detection algorithms like Canny later on, It's better to normalize our data so the algorithms can perform better and not put muc count to outliers\n",
        "def normalizing(T1):\n",
        "  T1_normalized = (T1 - np.min(T1)) / (np.max(T1) - np.min(T1))\n",
        "  return T1_normalized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tNmHvJWDuRhc"
      },
      "outputs": [],
      "source": [
        "#We now start the segmentation process, beginning with smoothing using Gaussian filter. scipy's gaussian_filter works better in 3D images\n",
        "def smoothing(slice_normalized, sigma = 1):\n",
        "   if slice_normalized.ndim == 3:\n",
        "      slice_smoothed = gaussian_filter(slice_normalized, sigma=sigma)\n",
        "\n",
        "   else:\n",
        "\n",
        "       slice_smoothed = cv2.GaussianBlur(slice_normalized, (5, 5), 0)\n",
        "\n",
        "   return slice_smoothed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AfIXtKSuj8Fm"
      },
      "outputs": [],
      "source": [
        "#For 3D, applying the advanced algorithm of scipy's Multi level Otsu Thresholding to better handle 3D MRI images.\n",
        "def otsu_thresholding(slice_smoothed):\n",
        "    if slice_smoothed.ndim == 3:\n",
        "      # Compute multi-Otsu thresholds\n",
        "      thresholds = threshold_multiotsu(slice_smoothed)\n",
        "\n",
        "      # Digitize the image into discrete regions\n",
        "      thresholded = np.digitize(slice_smoothed, bins=thresholds)\n",
        "\n",
        "    else:\n",
        "        _, thresholded = cv2.threshold((slice_smoothed * 255).astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    return thresholded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Rhf2DH34qogx"
      },
      "outputs": [],
      "source": [
        "# Showcasing the outcome of applying otsu on our smoothed slice\n",
        "def showcase_thresholded(thresholded, slice_smoothed):\n",
        "  thresholded_img = thresholded * slice_smoothed\n",
        "\n",
        "  return thresholded_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zIlbvgbMHDgD"
      },
      "outputs": [],
      "source": [
        "#We apply canny edge detection. Given the nature of our ground truth, morphological processes such as hole filling and remove small objects has managed to achieve an improved accuracy.\n",
        "def applying_canny(thresholded_img, sigma=2, min_size = 100):\n",
        "    if thresholded_img.ndim == 3:\n",
        "\n",
        "        # Create an empty array to store edges\n",
        "        edges = np.zeros_like(thresholded_img, dtype=bool)\n",
        "\n",
        "        # Apply Canny slice by slice along the depth (3rd dimension)\n",
        "        for i in range(thresholded_img.shape[2]):\n",
        "            edges_ = canny(thresholded_img[:, :, i].astype(np.float64), sigma=sigma)  # Apply Canny on a 2D slice\n",
        "            edges_ = binary_dilation(edges_)  # Dilate the edges\n",
        "            edges_ = binary_fill_holes(edges_)  # Fill holes in the edges\n",
        "            edges_ = remove_small_objects(edges_, min_size=min_size)  # Remove small objects\n",
        "            edges[:, :, i] = edges_  # Store the processed edges\n",
        "\n",
        "    else:\n",
        "        edges = canny(thresholded_img, sigma=2)\n",
        "        # Dilate the edges\n",
        "        edges = ndi.binary_dilation(edges)\n",
        "\n",
        "        # Fill holes in the edges\n",
        "        edges = ndi.binary_fill_holes(edges)\n",
        "\n",
        "        # remove small objects\n",
        "        edges = remove_small_objects(edges, min_size=100)\n",
        "\n",
        "\n",
        "    return edges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9k_keZ4zHGT2"
      },
      "outputs": [],
      "source": [
        "#Showcasing the effect of applying Canny edge detection to our image\n",
        "def showcasing_canny(slice_normalized, edges):\n",
        "\n",
        "    # Multiply the original image by the edges to mask it\n",
        "    img_thresholded = slice_normalized * edges  # Element-wise multiplication\n",
        "\n",
        "    return img_thresholded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cb867snGuv24"
      },
      "outputs": [],
      "source": [
        "#Define k-means segmentation so we can apply it to the image\n",
        "def kmeans_segmentation(image, n_clusters=6):\n",
        "    # Reshape the image to a 2D array\n",
        "    X = image.reshape(-1, 1)\n",
        "\n",
        "    # Fit KMeans to the data\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "\n",
        "    # Predict the labels for the data\n",
        "    labels = kmeans.fit_predict(X)\n",
        "\n",
        "    # Reshape the labels to the original image shape\n",
        "    labels = labels.reshape(image.shape)\n",
        "\n",
        "    # Get the centroids of the clusters\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    # Order the centroids and return the indices\n",
        "    order = np.argsort(centroids, axis=0)\n",
        "\n",
        "    return labels, order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t0ikjg8AvHBk"
      },
      "outputs": [],
      "source": [
        "#Creating a temporal_mask dictionary so we can ensure efficient mapping. This step increaed the segmentation accuracy dramatically given that it allows us to use masks, where each mask is 1 and the rest is zero.  By combining them together, the noise is reduced.\n",
        "def temporal_mask_creation(cluster_labels, order):\n",
        "  temporal_masks = {}\n",
        "  temporal_masks[\"0\"] = (cluster_labels == order[0]).astype(int)\n",
        "  temporal_masks[\"1\"] = (cluster_labels == order[1]).astype(int)\n",
        "  temporal_masks[\"2\"] = (cluster_labels == order[2]).astype(int)\n",
        "  temporal_masks[\"3\"] = (cluster_labels == order[3]).astype(int)\n",
        "  temporal_masks[\"4\"] = (cluster_labels == order[4]).astype(int)\n",
        "  temporal_masks[\"5\"] = (cluster_labels == order[5]).astype(int)\n",
        "  return temporal_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1NeVoZcmvSH_"
      },
      "outputs": [],
      "source": [
        "#Defining functions to help in plotting our masks, as well as cobining the masks to give our final segmented output\n",
        "def plot_masks(temporal_masks, rows=1, cols=2, slice_id=None):\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(12, 6))\n",
        "\n",
        "    fig.suptitle('Temporal Masks')\n",
        "\n",
        "    flatten_axes = axes.flat\n",
        "    for ax, (key, mask) in zip(flatten_axes, temporal_masks.items()):\n",
        "        # Check if the mask has more than 2 dimensions and slice it to 2D if needed\n",
        "        if mask.ndim > 2:\n",
        "            mask = mask[:, :, 0]  # Select the first slice of the 3D array\n",
        "\n",
        "        if slice_id is not None:\n",
        "            mask = mask[:, :, slice_id]\n",
        "        ax.imshow(mask, cmap='gray')\n",
        "        ax.set_title(f'Mask: {key}')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def temporal_masks2final_segmented_mask(temporal_masks, labels = range(6), slice_id = None):\n",
        "    if slice_id is not None:\n",
        "        segmented_labels = np.zeros_like(temporal_masks[\"0\"][:,:,0])\n",
        "    else:\n",
        "        segmented_labels = np.zeros_like(temporal_masks[\"0\"])\n",
        "\n",
        "    # Accumulate all the temporal masks in the segmented_labels\n",
        "    for label in labels:\n",
        "        mask = temporal_masks[str(label)]\n",
        "        if slice_id is not None:\n",
        "            mask = mask[:,:,slice_id]\n",
        "        segmented_labels[mask == 1] = label\n",
        "\n",
        "    return segmented_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S0RG4WgNvfV3"
      },
      "outputs": [],
      "source": [
        "#function to showcase our final segmented image\n",
        "def showcase_segmented_image(temporal_masks):\n",
        "  segmented_img = temporal_masks2final_segmented_mask(temporal_masks)\n",
        "\n",
        "  return segmented_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7I6LoUuXkGn3"
      },
      "outputs": [],
      "source": [
        "#Defining our Dice metrics\n",
        "def dice_coefficient(pred, truth):\n",
        "    pred = pred > 0  # Ensure binary format\n",
        "    truth = truth > 0  # Ensure binary format\n",
        "    intersection = np.sum(pred * truth)\n",
        "    return 2 * intersection / (np.sum(pred) + np.sum(truth))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-outS0yhkI9Y"
      },
      "outputs": [],
      "source": [
        "#Defining our Jaccard metrics\n",
        "def jaccard_index(pred, truth):\n",
        "    pred = pred > 0\n",
        "    truth = truth > 0\n",
        "    intersection = np.sum(pred * truth)\n",
        "    union = np.sum(pred + truth) - intersection\n",
        "    return intersection / union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1VkGrsNhk2rt"
      },
      "outputs": [],
      "source": [
        "#Defining our accuracy metrics\n",
        "def pixel_accuracy(pred, truth):\n",
        "\n",
        "    pred = pred > 0  # Ensure binary format\n",
        "    truth = truth > 0  # Ensure binary format\n",
        "\n",
        "    correct = np.sum(pred == truth)  # Count matching pixels\n",
        "    total = truth.size  # Total number of pixels\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6OWWsd4y4LYN"
      },
      "outputs": [],
      "source": [
        "#Showcasing the performance of our segmentation algoirthm vs. the ground truth\n",
        "def compare_label_distributions(ground_truth, prediction, num_classes):\n",
        "\n",
        "    # Count label occurrences in ground truth\n",
        "    gt_labels, gt_counts = np.unique(ground_truth, return_counts=True)\n",
        "    gt_distribution = np.zeros(num_classes)\n",
        "    gt_distribution[gt_labels] = gt_counts\n",
        "\n",
        "    # Count label occurrences in prediction\n",
        "    pred_labels, pred_counts = np.unique(prediction, return_counts=True)\n",
        "    pred_distribution = np.zeros(num_classes)\n",
        "    pred_distribution[pred_labels] = pred_counts\n",
        "\n",
        "    # Normalize to percentage if needed\n",
        "    gt_percentage = (gt_distribution / np.sum(gt_distribution)) * 100\n",
        "    pred_percentage = (pred_distribution / np.sum(pred_distribution)) * 100\n",
        "\n",
        "    # Plot the distributions\n",
        "    labels = [f\"Label {i}\" for i in range(num_classes)]\n",
        "    x = np.arange(num_classes)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    ax.bar(x - 0.2, gt_percentage, width=0.4, label='Ground Truth (%)', color='blue')\n",
        "    ax.bar(x + 0.2, pred_percentage, width=0.4, label='Prediction (%)', color='orange')\n",
        "\n",
        "    # Add labels, legend, and title\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.set_xlabel(\"Class Labels\")\n",
        "    ax.set_ylabel(\"Percentage of Pixels (%)\")\n",
        "    ax.set_title(\"Label Distribution: Ground Truth vs Prediction\")\n",
        "    ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 1: 2D Segmentation: Now we start the 2D segmentation process. Calling all the functions above and showcaisng results.**"
      ],
      "metadata": {
        "id": "6yRGogp5JnnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = loadmat('Brain.mat')\n",
        "T1 = data['T1']\n",
        "label = data['label']"
      ],
      "metadata": {
        "id": "dfvF5iYXJyq6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a segmentation function that applies the whol steps\n",
        "def full_segmentation_2d(slice_idx):\n",
        "\n",
        "  slice_data = T1[..., slice_idx]\n",
        "  ground_truth = label[..., slice_idx]\n",
        "\n",
        "  # Collect images, titles, and colormaps for visualization\n",
        "  images = []\n",
        "  titles = []\n",
        "  colormaps = []\n",
        "\n",
        "  # Step 1: Normalizing\n",
        "  T1_normalized = normalizing(T1)\n",
        "  slice_normalized = T1_normalized[..., slice_idx]\n",
        "  images.append(slice_normalized)\n",
        "  titles.append(\"Normalized Slice\")\n",
        "  colormaps.append(\"gray\")\n",
        "\n",
        "  # Step 2: Gaussian Smoothing\n",
        "  slice_smoothed = smoothing(slice_normalized)\n",
        "  images.append(slice_smoothed)\n",
        "  titles.append(\"Smoothed Slice\")\n",
        "  colormaps.append(\"gray\")\n",
        "\n",
        "  # Step 3: Otsu Thresholding\n",
        "  thresholded = otsu_thresholding(slice_smoothed)\n",
        "  images.append(thresholded)\n",
        "  titles.append(\"Otsu Thresholding\")\n",
        "  colormaps.append(\"gray\")\n",
        "\n",
        "  # Step 3: Effect of Otsu Thresholding on Image\n",
        "  thresholded_img = showcase_thresholded(thresholded, slice_smoothed)\n",
        "  images.append(thresholded_img)\n",
        "  titles.append(\"Effect of thresholding on Image\")\n",
        "  colormaps.append(\"gray\")\n",
        "\n",
        "  # Step 4: Canny Edge Detection\n",
        "  edges = applying_canny(thresholded)\n",
        "  images.append(edges)\n",
        "  titles.append(\"Canny Edges\")\n",
        "  colormaps.append(\"gray\")\n",
        "\n",
        "  #For Option3 for 2D algorithm (not using morphological operations), comment the above canny edge detection part and uncomment the following:\n",
        "  # edges = canny(thresholded_img, sigma=5)\n",
        "  # images.append(edges)\n",
        "  # titles.append(\"Canny Edges\")\n",
        "  # colormaps.append(\"gray\")\n",
        "\n",
        "\n",
        "  # Step 5: Showcasing Canny Effect\n",
        "  img_thresholded = showcasing_canny(slice_normalized, edges)\n",
        "  images.append(img_thresholded)\n",
        "  titles.append(\"Effect of Canny on Image\")\n",
        "  colormaps.append(\"gray\")\n",
        "\n",
        "  # Step 6: K-means Segmentation\n",
        "  cluster_labels, order = kmeans_segmentation(img_thresholded, n_clusters=6)\n",
        "  temporal_masks = temporal_mask_creation(cluster_labels, order)\n",
        "  segmented_img = showcase_segmented_image(temporal_masks)\n",
        "  images.append(segmented_img)\n",
        "  titles.append(\"Segmented Image\")\n",
        "  colormaps.append(\"viridis\")\n",
        "\n",
        "  #For Option2 in 2D Segmentation (not using dictionary-bases temporal masks after Kmeans), comment the above Kmeans and uncomment the below\n",
        "  # slice_flat = img_thresholded.flatten().reshape(-1, 1)\n",
        "  # kmeans = KMeans(n_clusters=6, random_state=0)\n",
        "\n",
        "  # # Predict the labels for the data\n",
        "  # kmeans_labels = kmeans.fit_predict(slice_flat)\n",
        "\n",
        "  # segmented_img = kmeans_labels.reshape(img_thresholded.shape)\n",
        "\n",
        "\n",
        "  # Step 8: Metrics\n",
        "  dice_score = dice_coefficient(segmented_img, ground_truth)\n",
        "  jaccard_score = jaccard_index(segmented_img, ground_truth)\n",
        "  accuracy_score = pixel_accuracy(segmented_img, ground_truth)\n",
        "\n",
        "\n",
        "  return temporal_masks, segmented_img, dice_score, jaccard_score, accuracy_score, ground_truth, images, titles, colormaps"
      ],
      "metadata": {
        "id": "slTyuDzAJlBt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a function to showcase all segmentation process in a grid\n",
        "def showcase_in_grid(images, titles, rows=2, cols=4, colormaps=None):\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        cmap = colormaps[i] if colormaps else 'gray'\n",
        "        axes[i].imshow(img, cmap=cmap)\n",
        "        axes[i].set_title(title)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    # Turn off unused axes\n",
        "    for i in range(len(images), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ghWpy_pLJw_2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loop throigh ths slices, showcase each final segmented slice and its corrresponding score\n",
        "metrics_2D = []\n",
        "for slice_idx in range(T1.shape[2]):\n",
        "  temporal_masks, segmented_img, dice_score, jaccard_score, accuracy_score, ground_truth, images, titles, colormaps= full_segmentation_2d(slice_idx)\n",
        "  print(f\"Slice {slice_idx}\")\n",
        "  print(f\"Dice Coefficient: {dice_score:.3f}\")\n",
        "  print(f\"Jaccard Index: {jaccard_score:.3f}\")\n",
        "  print(f\"Pixel Accuracy: {accuracy_score:.3f}\")\n",
        "\n",
        "  metrics_2D.append({\n",
        "              \"Slice Index\": slice_idx,\n",
        "              \"Dice Coefficient\": dice_score,\n",
        "              \"Jaccard Index\": jaccard_score,\n",
        "              \"Pixel Accuracy\": accuracy_score\n",
        "          })\n",
        "\n",
        "  plot_masks(temporal_masks, rows=2, cols=4)\n",
        "  plt.imshow(segmented_img)\n",
        "  plt.title('Segmented Output')\n",
        "  plt.colorbar(ticks=range(6), label=\"Labels (0-5)\")\n",
        "  plt.show()\n",
        "  print(\"---------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VTy1MIvDJ5ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loop throigh ths slices, showcaisng all process and segmented result\n",
        "for slice_idx in range(T1.shape[2]):\n",
        "  print(f\"Slice {slice_idx}\")\n",
        "  temporal_masks, segmented_img, dice_score, jaccard_score, accuracy_score, ground_truth, images, titles, colormaps = full_segmentation_2d(slice_idx)\n",
        "\n",
        "  showcase_in_grid(images, titles, rows=2, cols=4, colormaps=colormaps)"
      ],
      "metadata": {
        "id": "bXuj7ILxJ8fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Showcasing comparisons via metrics such as: Dice, Jaccard, and pixel accuracy.**"
      ],
      "metadata": {
        "id": "I0OA8vbdKPQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_metrics_table(metrics, num_slices):\n",
        "  metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "      # Display the table\n",
        "  print(\"\\nSegmentation Metrics for All Slices:\\n\")\n",
        "  print(metrics_df)\n",
        "  metrics_df.to_csv(\"segmentation_metrics.csv\", index=False)\n",
        "\n",
        "num_slices = T1.shape[2]\n",
        "display_metrics_table(metrics_2D, num_slices)"
      ],
      "metadata": {
        "id": "YXEX9nyHKB-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through all slice indices\n",
        "for slice_idx in range(num_slices):\n",
        "      # Call the full_segmentation function for the current slice ti compare the labels (classes)\n",
        "      temporal_masks, segmented_img, dice_score, jaccard_score, accuracy_score, ground_truth, images, titles, colormaps = full_segmentation_2d(slice_idx)\n",
        "      compare_label_distributions(ground_truth, segmented_img, num_classes = 6)\n",
        "\n"
      ],
      "metadata": {
        "id": "XIzDFqfeKE6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 3: 3D Segmentation Process**"
      ],
      "metadata": {
        "id": "ZTOQDrWJKLSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a segmentation function that applies the whole steps\n",
        "def full_segmentation_3d(slice):\n",
        "    slice_data = T1\n",
        "    ground_truth = label\n",
        "\n",
        "    # List to store intermediate results and titles\n",
        "    images = []\n",
        "    titles = []\n",
        "    colormaps = [] #To showcase the images\n",
        "\n",
        "    # Step 1: Gaussian Normalizaing\n",
        "    slice_normalized = normalizing(T1)\n",
        "    images.append(slice_normalized[:, :, slice_normalized.shape[2] // 2])\n",
        "    titles.append(\"Normalized Slice\")\n",
        "    colormaps.append(\"gray\")\n",
        "\n",
        "    # Step 2: Smoothing\n",
        "    slice_smoothed = smoothing(slice_normalized)\n",
        "    images.append(slice_smoothed[:, :, slice_smoothed.shape[2] // 2])\n",
        "    titles.append(\"Gaussian Smoothed Slice\")\n",
        "    colormaps.append(\"gray\")\n",
        "\n",
        "    # Step 3: Otsu Thresholding\n",
        "    thresholded = otsu_thresholding(slice_smoothed)\n",
        "    thresholded_img = showcase_thresholded(thresholded, slice_smoothed)\n",
        "    images.append(thresholded_img[:, :, thresholded_img.shape[2] // 2])\n",
        "    titles.append(\"Otsu Thresholded Image\")\n",
        "    colormaps.append(\"grey\")\n",
        "\n",
        "    # Step 4: Apply Canny Edge Detection\n",
        "    edges = applying_canny(thresholded_img)\n",
        "    images.append(edges[:, :, edges.shape[2] // 2])\n",
        "    titles.append(\"Canny Edges\")\n",
        "    colormaps.append(\"gray\")\n",
        "\n",
        "    # Step 5: Showcase Canny Effect\n",
        "    img_thresholded = showcasing_canny(slice_normalized, edges)\n",
        "    images.append(img_thresholded[:, :, img_thresholded.shape[2] // 2])\n",
        "    titles.append(\"Masked Edges\")\n",
        "    colormaps.append(None)\n",
        "\n",
        "    # Step 6: K-means Segmentation\n",
        "    cluster_labels, order = kmeans_segmentation(thresholded_img, n_clusters=6)\n",
        "    temporal_masks = temporal_mask_creation(cluster_labels, order)\n",
        "    segmented_img = showcase_segmented_image(temporal_masks)\n",
        "    images.append(segmented_img[:, :, segmented_img.shape[2] // 2])\n",
        "    titles.append(\"Segmented Image\")\n",
        "    colormaps.append(\"viridis\")\n",
        "\n",
        "    # Showcase all results in a grid\n",
        "    showcase_in_grid(images, titles, rows=2, cols=4, colormaps=colormaps)\n",
        "\n",
        "    # Step 7: Compare Label Distributions (shown after the grid)\n",
        "    compare_label_distributions(ground_truth, segmented_img, num_classes=6)\n",
        "\n",
        "    # Step 7: Metrics\n",
        "    dice_score = dice_coefficient(segmented_img, ground_truth)\n",
        "    jaccard_score = jaccard_index(segmented_img, ground_truth)\n",
        "    accuracy_score = pixel_accuracy(segmented_img, ground_truth)\n",
        "\n",
        "    return temporal_masks, segmented_img, dice_score, jaccard_score, accuracy_score"
      ],
      "metadata": {
        "id": "W0LxPPUWhgEp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting grid to showcase all results\n",
        "def showcase_in_grid_3d(images, titles, rows=2, cols=4, colormaps=None):\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
        "    axes = axes.flatten()  # Flatten to index easily\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        if isinstance(img, np.ndarray):  # If it's an image\n",
        "            cmap = colormaps[i] if colormaps else 'gray'  # Default to grayscale\n",
        "            axes[i].imshow(img, cmap=cmap)\n",
        "            axes[i].set_title(title)\n",
        "            axes[i].axis('off')\n",
        "        elif isinstance(img, plt.Figure):  # If it's a Matplotlib figure\n",
        "            # Render the plot into the grid\n",
        "            img.canvas.draw()\n",
        "            axes[i].imshow(np.array(img.canvas.renderer.buffer_rgba()))\n",
        "            axes[i].axis('off')\n",
        "            axes[i].set_title(title)\n",
        "\n",
        "    # Turn off unused axes\n",
        "    for i in range(len(images), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MSXlCIjdhk6X"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Showcasing results\n",
        "slice = T1\n",
        "\n",
        "#Showcaisng all segmentation steps taken\n",
        "temporal_masks, segmented_img, dice_score, jaccard_score, accuracy_score = full_segmentation_3d(slice)\n",
        "\n",
        "metrics_3D = []\n",
        "metrics_3D.append({\n",
        "              \"Slice Index\": slice_idx,\n",
        "              \"Dice Coefficient\": dice_score,\n",
        "              \"Jaccard Index\": jaccard_score,\n",
        "              \"Pixel Accuracy\": accuracy_score\n",
        "          })\n",
        "\n",
        "#Metrics\n",
        "print(\"-------------- Metrics -----------------\")\n",
        "print(f\"Dice Coefficient: {dice_score:.3f}\")\n",
        "print(f\"Jaccard Index: {jaccard_score:.3f}\")\n",
        "print(f\"Pixel Accuracy: {accuracy_score:.3f}\")\n",
        "print(\"----------------------------------------\")\n",
        "\n",
        "#Showcasing segmented image\n",
        "plt.imshow(segmented_img[:, :, segmented_img.shape[2] // 2])\n",
        "plt.title('Segmented Output')\n",
        "plt.colorbar(ticks=range(6), label=\"Labels (0-5)\")\n",
        "plt.show()\n",
        "\n",
        "#Showcasing the temporal masks used to hold the model labels\n",
        "plot_masks(temporal_masks, rows=2, cols=4)"
      ],
      "metadata": {
        "id": "lByMs4FihthN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing between the performance of our 2D and 3D Segmentation Process**"
      ],
      "metadata": {
        "id": "HQBnLNqyX_4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total slices\n",
        "num_slices = T1.shape[2]\n",
        "# Display side-by-side tables\n",
        "display_metrics_table(metrics_3D, num_slices)"
      ],
      "metadata": {
        "id": "Da6FH7mBUvjN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPJK2zVdFRGMap3RzDQsqI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}